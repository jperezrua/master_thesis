\relax 
\@input{tex/header.aux}
\@input{tex/abstract.aux}
\@input{tex/about.aux}
\citation{c16}
\citation{c16}
\citation{c23}
\citation{c17}
\citation{c17}
\citation{c34}
\citation{c38}
\citation{c41}
\citation{c17}
\citation{c25}
\citation{c16}
\citation{c17}
\citation{c20}
\citation{c22}
\citation{c16}
\citation{c23}
\citation{c24}
\citation{c25}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Problem definition}{2}}
\newlabel{sec:definition}{{1.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces  Object flow definition diagram. Top: Original frames with the tracker state, which indicates the object global motion (green arrow). Bottom: The object region is identified, and a dense motion field is obtained within its boundaries.}}{2}}
\newlabel{diagram}{{1.1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Objectives}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Document organization}{3}}
\citation{c16}
\citation{c16}
\citation{c23}
\citation{c22}
\citation{c22}
\citation{c23}
\citation{c24}
\citation{c25}
\citation{c26}
\citation{c16}
\citation{c23}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background and Related Work}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:background}{{2}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Object Tracking}{4}}
\citation{c16}
\citation{c16}
\citation{c23}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Sequences used to evaluate object trackers in \cite  {c16}. }}{5}}
\newlabel{tr_db}{{2.1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces  Performance summary for the top 15 trackers benchmarked in \cite  {c16}, initialized with different size of bounding box by factors of 0.8, 0.9, 1.0, 1.1 and 1.2. }}{5}}
\newlabel{tr_per}{{2.2}{5}}
\citation{c23}
\citation{c23}
\citation{c25}
\citation{c23}
\citation{c17}
\citation{c17}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Tracking-by-detection methods}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Usual approaches for tracking-by-detection methods. Right: generate a set of samples and, depending on the type of learner, produce training labels. Left: Structured output methods avoid these steps by operating directly in the tracking output. Extracted from \cite  {c23}.}}{6}}
\newlabel{tr_tbd}{{2.3}{6}}
\citation{c17}
\citation{c27}
\citation{c31}
\citation{c5}
\citation{c17}
\citation{c29}
\citation{c30}
\citation{c32}
\citation{c28}
\citation{c17}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Optical Flow}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Frame pairs used to evaluate optical flow methods in \cite  {c17}, Ground truth flow coded with the proposed flow coding. }}{7}}
\newlabel{tr_db}{{2.4}{7}}
\newlabel{eq_ener}{{2.1}{7}}
\citation{c17}
\citation{c17}
\citation{c21}
\citation{c40}
\citation{c17}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  Performance summary for the top 15 opt. flow methods benchmarked in \cite  {c17} by interpolation error. }}{8}}
\newlabel{of_per}{{2.5}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Simple Flow}{8}}
\newlabel{eq_simple}{{2.2}{8}}
\citation{c33}
\citation{c34}
\citation{c14}
\citation{c18}
\citation{c34}
\citation{c34}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces  Results of the Simple Flow method in several datasets. }}{9}}
\newlabel{simple_of_m}{{2.6}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Object segmentation in video}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces  Results of the Simple Flow method in several datasets. }}{10}}
\newlabel{simple_of}{{2.7}{10}}
\citation{c33}
\citation{c34}
\citation{c36}
\citation{c35}
\citation{c39}
\citation{c27}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces  Sparse motion trajectories for segmentation. Results in several datasets \cite  {c34}. }}{11}}
\newlabel{pt_segment}{{2.8}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Related work}{11}}
\citation{c37}
\citation{c38}
\citation{c38}
\citation{c38}
\citation{c38}
\citation{c41}
\citation{c41}
\citation{c41}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces  Video editing with the method in \cite  {c38}. }}{12}}
\newlabel{soa1}{{2.9}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces  Video editing with the method in \cite  {c41}. }}{13}}
\newlabel{soa2}{{2.10}{13}}
\citation{c1}
\citation{c1}
\citation{c10}
\citation{c11}
\citation{c9}
\citation{c11}
\citation{c8}
\citation{c2}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Superpixel flow}{14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:suppix}{{3}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem definition}{14}}
\citation{c9}
\citation{c10}
\citation{c9}
\citation{c7}
\citation{c12}
\citation{c13}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Energy Formulation}{15}}
\newlabel{eq_prob}{{3.1}{15}}
\citation{c7}
\citation{c5}
\citation{c3}
\citation{c4}
\citation{c3}
\citation{c7}
\citation{c4}
\newlabel{eq_energy}{{3.2}{16}}
\newlabel{eq_Dp}{{3.3}{16}}
\newlabel{eq_Spq}{{3.4}{16}}
\citation{c3}
\citation{c4}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Energy Minimization}{17}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Superpixel flow minimization algorithm}}{18}}
\newlabel{algo2}{{1}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Matching Results}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The yellow lines show selected superpixel matching between pairs of consecutive frames in a video with the proposed method. The video frames go from right to left. The images are a close-up of the actual frame, to appreciate the details.}}{19}}
\newlabel{figurelabel_matches}{{3.1}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The coloured lines show selected superpixel matchings between a pair of distant frames in the Snow Shoes sequence.}}{19}}
\newlabel{figurelabel_matchessnow}{{3.2}{19}}
\citation{c22}
\citation{c16}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Object Flow Pipeline}{20}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:core}{{4}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Algorithm description}{20}}
\newlabel{sec:desc}{{4.1}{20}}
\citation{c18}
\citation{c14}
\citation{c18}
\citation{c14}
\citation{c15}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Block diagram of the proposed pipeline.}}{21}}
\newlabel{figurelabel_sys}{{4.1}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Background regions tracking and segmentation}{21}}
\newlabel{sec:segm}{{4.2}{21}}
\citation{c50}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Example image of points entering a tracking region (green) due to object motion in a video sequence.}}{22}}
\newlabel{figurelabel_entering}{{4.2}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Point tracking using an optical flow method.}}{22}}
\newlabel{pointtr}{{4.3}{22}}
\citation{c18}
\citation{c15}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Background regions tracking between a frames A and B}}{23}}
\newlabel{algo1}{{2}{23}}
\citation{c18}
\citation{c19}
\citation{c17}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Background segments automatic labelling and propagation, the flow goes from left to right.}}{24}}
\newlabel{figurelabel_spflow}{{4.4}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Segmentation results}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Segmentation through the sequence “Walking Couple” (Yellow contour) initialized in the man’s head. The yellow box correspond to the tracker output. The labelled background superpixel are not shown for clarity.}}{25}}
\newlabel{figurelabel_walking}{{4.5}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Face segmentation in the “Amelie Retro” and the “Snow shoes” sequences in several different frames, and T-shirt extraction from Tennis sequence. For each group, the Top Row: One-iteration window-based graph-cuts; and the Bottom Row: One-iteration graph-cuts initialized with superpixel tracking.}}{26}}
\newlabel{figurelabel_comp}{{4.6}{26}}
\citation{c17}
\citation{c17}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Flow estimation}{27}}
\newlabel{sec:core}{{4.3}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Object flow with the color code of \cite  {c17} (bottom) for frames in the Puppy sequence (up). }}{27}}
\newlabel{of}{{4.7}{27}}
\citation{c21}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces  Object flow for several frames of the MPI\_S1 sequence. The flow is shown enlarged for better details.}}{28}}
\newlabel{of2}{{4.8}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Feedback for tracking methods}{29}}
\newlabel{sec:feedback}{{4.4}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces  Simple object flow algorithm diagram.}}{30}}
\newlabel{sof_d}{{4.9}{30}}
\citation{c25}
\citation{c25}
\citation{c25}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Top row: First and last frames used from the Amelia sequence. Bottom row: From left to right: Groundtruth patch; patch generated with the basic object flow combining the {\it  Struck} Tracker and the {\it  TVL1} optical flow; and patch generated with the globally computed {\it  TVL1} optical flow.}}{31}}
\newlabel{of_nose}{{4.10}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces An overview on how tracking-by-detection methods try to deal with occlusions. Extracted from \cite  {c25}.}}{31}}
\newlabel{tr_mil}{{4.11}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Struck tracker in the Walking Couple sequence. Top: Original Implementation. Bottom: Struck tracker with sampling refinement by background regions tracking.}}{32}}
\newlabel{tr_strucktest}{{4.12}{32}}
\citation{c20}
\citation{c20}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Implementation Details and Evaluation}{34}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{5}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Experiments}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Reconstruction results from integrated flow in 4 sequences. In descending order: Amelia Retro, Boy, Walking, Puppy. From Left to Right: Annotated object, Backward object flow, Backward optical flow, Forward object flow, Backward optical flow.}}{35}}
\newlabel{sample}{{5.1}{35}}
\citation{c44}
\citation{c46}
\citation{c46}
\citation{c45}
\citation{c25}
\citation{c47}
\citation{c23}
\citation{c48}
\citation{c31}
\citation{c30}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Handmade contour (yellow) in the Amelia dataset used as ground truth.}}{36}}
\newlabel{handmade}{{5.2}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Implementation details}{36}}
\citation{c32}
\citation{c50}
\citation{c21}
\citation{c28}
\citation{c49}
\citation{c29}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces PSNR graphs for reconstructed images using Object flow and the Simple Optical Flow for 4 sequences. From left to right and up to bottom: Puppy Seq.; Amelia Retro Seq.; Boy Seq.; Walking Seq.}}{38}}
\newlabel{of_res}{{5.3}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Top: The first frame and the accumulated flows are used to reconstruct objects in the frame number 30. The used methods from left to right: Groundtruth object, Object flow, TVL1, Block Matching, Brox, Farneback and Simple Flow. Bottom: First and frame\#30. The reconstructions are performed using backward accumulation of the flows.}}{39}}
\newlabel{compare2}{{5.4}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces PSNR graphs for reconstructed images using Object flow and the different Optical Flow techniques for the Amelia sequence. }}{39}}
\newlabel{of_res2}{{5.5}{39}}
\citation{c43}
\citation{c43}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Applications}{40}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:apps}{{6}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Video editing}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Structure from motion}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces  Selected frames in the Dmitry test sequence for video editing. Top: Inserted logo. Bottom: original frames}}{41}}
\newlabel{pt_seg}{{6.1}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces  Selected frames in the Juan test sequence for video editing. The logo of the University of Burgundy is inserted in the sequence. }}{41}}
\newlabel{pt_seg2}{{6.2}{41}}
\citation{c43}
\citation{c42}
\newlabel{eq_dfc}{{6.1}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces  SFM based on the object flow matches in the Puppy dataset. Top: views of the computed structure. Bottom: Used frames. }}{42}}
\newlabel{sfm2}{{6.3}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces  SFM based on the object flow matches in the JuanFace dataset. Top: views of the computed structure. Bottom: Used frames. }}{44}}
\newlabel{sfm3}{{6.4}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces  SFM based on the Sift matches between frames. Top: views of the computed structure. Bottom: Used frames. }}{45}}
\newlabel{sfm4}{{6.5}{45}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions}{46}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:conclusion}{{7}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Discussion}{46}}
\newlabel{sec:discussion}{{7.1}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Final remarks}{47}}
\newlabel{sec:remarks}{{7.2}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces  Sequence with different difficult cases for flow estimation methods: Autobalanace, illumination changes, specularities. }}{47}}
\newlabel{of_errors}{{7.1}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Close-up to the generated artifacts due to the illumination changes and specular reflections. }}{48}}
\newlabel{zoom_errors}{{7.2}{48}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}UML Diagram}{49}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{class}{{A}{49}}
\bibstyle{plain}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Segmentation in Video}{50}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:seg}{{B}{50}}
\newlabel{othersegm1}{{B}{50}}
\newlabel{othersegm1}{{B}{51}}
\bibcite{c1}{1}
\bibcite{c2}{2}
\bibcite{c3}{3}
\bibcite{c4}{4}
\bibcite{c5}{5}
\bibcite{c6}{6}
\bibcite{c7}{7}
\bibcite{c8}{8}
\bibcite{c9}{9}
\bibcite{c10}{10}
\bibcite{c11}{11}
\bibcite{c12}{12}
\bibcite{c13}{13}
\bibcite{c14}{14}
\bibcite{c15}{15}
\bibcite{c16}{16}
\bibcite{c17}{17}
\bibcite{c18}{18}
\bibcite{c19}{19}
\bibcite{c20}{20}
\bibcite{c21}{21}
\bibcite{c22}{22}
\bibcite{c23}{23}
\bibcite{c24}{24}
\bibcite{c25}{25}
\bibcite{c26}{26}
\bibcite{c27}{27}
\bibcite{c28}{28}
\bibcite{c29}{29}
\bibcite{c30}{30}
\bibcite{c31}{31}
\bibcite{c32}{32}
\bibcite{c33}{33}
\bibcite{c34}{34}
\bibcite{c35}{35}
\bibcite{c36}{36}
\bibcite{c37}{37}
\bibcite{c38}{38}
\bibcite{c39}{39}
\bibcite{c40}{40}
\bibcite{c41}{41}
\bibcite{c42}{42}
\bibcite{c43}{43}
\bibcite{c44}{44}
\bibcite{c45}{45}
\bibcite{c46}{46}
\bibcite{c47}{47}
\bibcite{c48}{48}
\bibcite{c49}{49}
\bibcite{c50}{50}
\@writefile{toc}{\contentsline {chapter}{\numberline {Bibliography\hspace  {-96pt}}}{55}}
